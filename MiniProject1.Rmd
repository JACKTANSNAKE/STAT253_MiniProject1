---
title: "Mini-Project 1"
author: Jack Tan, Debbie Sun, Alex Denzler, Phuong Nguyen
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r message = FALSE}
#Load packages used for analysis
library(ggplot2)
library(dplyr)
library(caret)
library(RANN)
library(stringr)
```



\
\



## Part 1: Ready the data
```{r, warning = FALSE}
airbnb <- read.csv("https://www.macalester.edu/~ajohns24/data/NYC_airbnb_kaggle.csv")
nbhd <- read.csv("https://www.macalester.edu/~ajohns24/data/NYC_nbhd_kaggle.csv")
airbnb_complete <- left_join(nbhd, airbnb, by = c("neighbourhood" = "neighbourhood_cleansed"))
dim(airbnb_complete)
```

### Data wrangling

#### Clean up the data
```{r message = FALSE, warning = FALSE, cache = TRUE}
airbnb_complete <- airbnb_complete %>% 
  filter(price < 1000) %>%
  select(-id, -longitude, -latitude, -neighbourhood,-calendar_updated, -square_feet, -amenities) %>% 
  mutate(amenity_count = str_count(amenities, ',') + 1)

max(airbnb_complete$amenity_count)

dim(airbnb_complete)
```

We deselected idenfitication variables, `id`, `longitude` and `latitude` because these cannot be analyzed. While location can illuminate some of the price differences, we determined that `longitude` and `latitude` values of these listings would be very similar because of their closeness (within NYC) while `neighboorhood_group` may better catch the geographical effect than these two variables. Similarly, we removed `neighboorhood` from our dataset because `neighborhood_group` or borough is expected to reflect its effect (although running LASSO with `neighbourhood` resulted in a model with $R^2$ of 0.68). `calendar_updated`, how recently updated the listing details are, was also dropped - we determined that would not be useful for our predictive model of price. `square_feet` on the area of the listing would be a very useful predictor, but we also removed it because the missing 

We also deselected `amenities` since there are maximum 87 catergories of amenities so we would technically get $\sum_{k=1}^{87} {87 \choose k} - 1$  different reference levels for this single variable and make the resulting model overly complicated and not interpretable. However, we believe that might exist a relationship between the number of amenities an airbnb has and its price, since intuitively pricey airbnbs should have more services. Therefore, we counted the number of `amenities`, as `amenity_count`, in the dataset and dropped amenities.



#### One example of correlation (catergorical)
```{r}
ggplot(airbnb_complete, aes(x = host_is_superhost, y = price)) + 
  geom_boxplot()

airbnb_complete <- airbnb_complete %>% 
  filter(host_response_rate != "") %>%
  #filter(host_is_superhost != "") %>%
  #filter(host_has_profile_pic != "") %>%
  #filter(host_response_time != "") %>%
  #filter(require_guest_profile_picture != "")

  
#After filtering the blank data ""
ggplot(airbnb_complete, aes(x = host_is_superhost, y = price)) + 
  geom_boxplot()
```

Upon further examination, we identified many blank values ("") in several of our categorical variables. For example, `host_response_rate` originally had 4 levels, "T", "F", "NA", and "". Other variables that had the same problem were `host_is_superhost`, `host_has_profile_pic`, `host_response_time`, and `require_guest_profile_picture`. Because "" are impossible to interpret (we do not know what it stands for, especially in the presence of "NA"") and analyze (catergorical variables cannot be imputed using the KNN method), we tried to filter out all datapoints with blank values for these variables. Surprisingly, the length of the dataset is the same with all five variables filtered of "" compared to if we only filter "host_response_rate" of "", implying that removal of all "" values in host_response_rate successfully filtered out "" for other variables. We assumed that the "" data in all five variables were the caused by technical issues when collecting the data. For simplicity, we only filtered `host_response_rate` so that we can eliminate all missing information in these predictors. 



#### Randomly choose 5000 datapoints to get a smaller dataset for analysis
```{r, cache = TRUE}
set.seed(253)
airbnb_5000 <- sample_n(airbnb_complete, 5000)
dim(airbnb_5000)
```



\
\
\
\
\
\



## Part 2: Analyze
### impute with KNN
```{r,cache=TRUE}
impute_info <- airbnb_5000 %>%
  select(-price,-amenity_count) %>%
  preProcess(method = "knnImpute")
airbnb_5000 <- predict(impute_info, newdata = airbnb_5000)
```

### Modeling with LASSO
```{r,cache=FALSE,warning = FALSE}
lambda_grid <- 10^seq(-3, 1, length = 100)

# Set the seed 
    set.seed(253)
    
    lasso_model_origin <- train(
      price ~ .,
      data = airbnb_5000,
      method = "glmnet",
      trControl = trainControl(method = "cv", number = 10, selectionFunction = "oneSE"),
      tuneGrid = data.frame(alpha = 1, lambda = lambda_grid),
      metric = "MAE",
      na.action = na.omit
    )
    
lasso_model_origin$results %>%
  filter(lambda == lasso_model_origin$bestTune$lambda)

# Combine residuals & predictions into data frame
result_df <- data.frame(resid = resid(lasso_model_origin), fitted = fitted(lasso_model_origin))

# Residual plot
ggplot(result_df, aes(x = fitted, y = resid)) + 
    geom_point() + 
    geom_hline(yintercept = 0)
```

We tried to predict `price` using a lasso model and chose the optimal model within one standard deviation to the best model in lasso algorithm as to simplify our model while maintaining a similar $R^2$. The $R^2$ of the lasso model is 0.5943, indicating that our model is moderately strong since almost 60 percent of the variability in price is explained by lasso model. Also, the residual plot is balanced on both sides of the residual line. 



### Modeling with LASSO with log(price)
```{r, cache=TRUE}
airbnb_5000$price <- log(airbnb_5000$price + 1)
```

```{r,cache=FALSE,warning = FALSE}
lambda_grid <- 10^seq(-3, 1, length = 100)

# Set the seed 
    set.seed(253)
    
    lasso_model <- train(
      price ~ .,
      data = airbnb_5000,
      method = "glmnet",
      trControl = trainControl(method = "cv", number = 10, selectionFunction = "oneSE"),
      tuneGrid = data.frame(alpha = 1, lambda = lambda_grid),
      metric = "MAE",
      na.action = na.omit
    )
    
lasso_model$results %>%
  filter(lambda == lasso_model$bestTune$lambda)

```

Improve Rsquared and residual plot

```{r message = FALSE, cache=TRUE}
model_coef <- coef(lasso_model$finalModel, lasso_model$bestTune$lambda)
#model_coef 
#It's a super long list of coeffs and we do not want them listed up in the report.

```

```{r message = FALSE, cache = TRUE}
lasso_model$bestTune$lambda
# Codebook for which variables the numbers correspond to

plot(lasso_model,xlim = c(0,0.025), ylim = c(0.3,0.32))

# Combine residuals & predictions into data frame
result_df <- data.frame(resid = resid(lasso_model), fitted = fitted(lasso_model))

 # Residual plot
ggplot(result_df, aes(x = fitted, y = resid)) + 
    geom_point() + 
    geom_hline(yintercept = 0)
```

By changing our LASSO model to the log scale, we were able to increase our $R^2$ from 0.507 to 0.595.


### Deselecting the variables considered insignificant by Lasso
```{r message = FALSE,cache=TRUE}
airbnb_5000_complete <- airbnb_5000 %>% 
  select(-host_response_rate,-host_is_superhost,-host_has_profile_pic,-is_location_exact,-property_type,-beds,-bed_type,-maximum_nights,-number_of_reviews,-cancellation_policy,-require_guest_profile_picture)
dim(airbnb_5000_complete)
```

### Least Square model to compare
```{r, cache=TRUE}
ls_model <- train(
    price ~ .,
    data = airbnb_5000_complete,
    method = "lm",
    trControl = trainControl(method = "cv", number = 10),
    na.action = na.omit
)

summary(ls_model)
ls_model$results$Rsquared
ls_model$resample%>%
  summarize(mean(MAE))
result_df_ls <- data.frame(resid = resid(ls_model), fitted = fitted(ls_model))

 # Residual plot
ggplot(result_df_ls, aes(x = fitted, y = resid)) + 
    geom_point() + 
    geom_hline(yintercept = 0)
```


The $R^2$ of least squares model is 0.598 which is similar to the lasso model. The least squares model is made up of only the coefficients that the LASSO deemed to be significant. Therefore, we are simply making the LASSO model more interpretable by turning it into a least squares model. The residuals for the least squared model shows the similar trend for the LASSO model.


### Removing the only catergorical variable that has problem with GAM
```{r,cache=TRUE,eval = fALSE}
airbnb_5000_complete <- airbnb_5000_complete %>% select(-room_type, -host_response_time)
```
<<<<<<< HEAD
Originally, the GAM algorithm did not like our airbnb_complete dataset. We thought there might be too many catergorical variables and it can't handle that much. We removed the less significant variables (according to the least squares model). After trial and error, we found that the only variable that GAM had a problem with was `room_type`, so we just removed it.
=======

Originally, the GAM algorithm does not like our airbnb_complete dataset. We thought there might be too many catergorical variables and it can't handle that much. So we started out removing multiple less significant variables out (according to the least square model). After trials and errors, we found that the only variable that had problem with GAM was room_type, so we just removed it.
>>>>>>> d0599951403b70407611a524da835900cba4f3c4

### Building the GAM model
```{r warning = FALSE, message = FALSE, fig.width = 8, fig.height = 12,eval = FALSE}
 # Set the seed
    set.seed(253)

 # Run the GAM
    gam_model <- train(
      price ~.,
      data = airbnb_5000_complete,
      method = "gamLoess",
      tuneGrid = data.frame(span = seq(0.1,1,length = 30), degree = 1),
      trControl = trainControl(method = "cv", number = 10, selectionFunction = "best"),
      metric = "MAE",
      na.action = na.omit
    )
```

### Showing the GAM results
```{r fig.width = 8, fig.height =12,eval = FALSE}
    # Calculate the CV MAE of the best model
    gam_model$results %>% 
      filter(span == gam_model$bestTune$span)
    gam_model$resample %>% 
      summarize(mean(MAE))
    
    par(mfrow = c(5,4))
    
    # Make plots
    plot(gam_model$finalModel)
```


The $R^2$ in the GAM model that we tried is 0.496 and its MAE is relatively larger than the other models; therefore, we decided to not use it in our analysis.



### Contrast with KNN
```{r, eval = FALSE}
set.seed(253)

# Run the KNN
knn_model <- train(
  price ~ .,
  data = airbnb_5000_complete,
  preProcess = c("center","scale"),
  method = "knn",
  tuneGrid = data.frame(k = c(1:19, seq(20, 100, by = 5), seq(150, 450, by = 50))),
  trControl = trainControl(method = "cv", number = 10, selectionFunction = "best"),
  metric = "MAE",
  na.action = na.omit
)
```

### Result of KNN
```{r, eval = FALSE}
knn_model$bestTune
knn_model$results %>% 
  filter(k == knn_model$bestTune$k)
```

Similar to the GAM model, KNN lacks interpretability and its $R^2$ is just slightly better than GAM. So we also decided to delete it from our analysis.


Our final model is least squares, which gave us an Rsquared value of 0.598.
```{r}
summary(least_squares)
```


\
\
\
\
\



## Part 3: Summarize


price ~ amenity_count
The coefficient of `amenity_count` in the LASSO model is 0.0051755. Thus, as `amenity_count` increases by 1, `price` multiplies by $e^(0.0051755) = 1.005189$. This is intuitive because as listings provide more amenities for guests hosts can increase the price. 

```{r}
mean(airbnb_5000_complete$amenity_count)
max(airbnb_5000_complete$amenity_count)
min(airbnb_5000_complete$amenity_count)
median(airbnb_5000_complete$amenity_count)
airbnb_5000_complete %>% filter(amenity_count == 64)
```


Relationship of all predictors to price in the model. When holding amenity_count constant, what other predictors contribute to price? Listings of important predictors. 


Using a combination of parametric worked and we were able to quantify the relationships of . 
- 

Why we think the variables made sense in the end.


\
\
\
\
\
\



## Part 4: Contributions



## Appendix

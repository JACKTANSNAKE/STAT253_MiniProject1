---
title: "Mini-Project 1"
author: Jack Tan
output: 
  html_document:
    toc: true
    toc_float: true
---
```{r message = FALSE, cache = TRUE}
library(ggplot2)
library(dplyr)
library(caret)
library(RANN)
library(stringr)
```

\
\
## Part 1: Ready the data
```{r}
airbnb <- read.csv("https://www.macalester.edu/~ajohns24/data/NYC_airbnb_kaggle.csv")
nbhd <- read.csv("https://www.macalester.edu/~ajohns24/data/NYC_nbhd_kaggle.csv")
airbnb_complete <- left_join(nbhd, airbnb, by = c("neighbourhood" = "neighbourhood_cleansed"))
dim(airbnb_complete)
```




### Deal with the data
```{r message = FALSE, warning= FALSE}
airbnb_complete <- airbnb_complete %>% 
  filter(price < 1000) %>%
  filter(host_response_rate != "") %>%
  mutate(amenity_count = str_count(amenities, ',') + 1) %>%
  #filter(host_is_superhost != "") %>%
  #filter(host_has_profile_pic != "") %>%
  #filter(host_response_time != "") %>%
  #filter(require_guest_profile_picture != "")
  select(-id,-longitude,-latitude,-amenities,-square_feet,-calendar_updated)
dim(airbnb_complete)
```

The "host_response_rate" variable initially has 3 answers, "T", "F", and no information. Since we can't interpret the option of no information, we choose to filter out all data points which has no information of this vairable. We also find out that "host_is_superhost", "host_has_profile_pic", "host_response_time", and "require_guest_profile_picture" all have the same issues, and we tried to filter out all data which have no information of these variables. Surprisingly, the dimension of the dataset is the same with the one that we only filter "host_response_rate"; therefore, we can assume that the data which have no information in "host_response_rate" also does not have information in other variables. For simplicity, we just filter "host_response_rate" so that we can eliminate all missing information in these predictors.

We also deselect id and calendar_updated because we think they have no influence on the price. Also, we drop lontitude and latitude because the data of each is very similar to itself since it's in the same city. We also deselect amenities since we don't think how each kind of amenities would affect the price significantly, but the number of amenities in each of the airbnb might do; therefore, we add the number of amenities, amenity_count, in the dataset and drop amenities.

```{r}
set.seed(253)
airbnb_5000 <- sample_n(airbnb_complete,5000)
dim(airbnb_5000)
```

\
\
\
\
\
\



## Part 2: Analyze
impute with KNN
```{r}
impute_info <- airbnb_5000 %>%
  select(-price) %>%
  preProcess(method = "knnImpute")
airbnb_5000 <- predict(impute_info, newdata = airbnb_5000)
```

model with LASSO
```{r}
lambda_grid <- 10^seq(-3, 1, length = 100)

# Set the seed 
    set.seed(253)
    
    lasso_model <- train(
      price ~ .,
      data = airbnb_5000,
      method = "glmnet",
      trControl = trainControl(method = "cv", number = 10, selectionFunction = "best"),
      tuneGrid = data.frame(alpha = 1, lambda = lambda_grid),
      metric = "MAE",
      na.action = na.omit
    )
    
lasso_model$resample %>% 
  summarize(mean(Rsquared))
```

```{r message = FALSE}
model_coef <- coef(lasso_model$finalModel, lasso_model$bestTune$lambda)
#model_coef 
#It's a super long list of coeffs and we do not want them listed up in the report.
```

### Deselecting the variables considered unsignificant by Lasso
```{r message = FALSE}
airbnb_5000_complete <- airbnb_5000 %>% 
  select(-host_response_time,-host_response_rate,-host_is_superhost,-host_has_profile_pic,-is_location_exact,-property_type,-beds,-bed_type,-maximum_nights,-cancellation_policy,-require_guest_profile_picture,-neighbourhood)
```

### Least Square model to compare
```{r}
ls_model <- train(
    price ~ .,
    data = airbnb_5000_complete,
    method = "lm",
    trControl = trainControl(method = "cv", number = 10),
    na.action = na.omit
)

summary(ls_model)
ls_model$resample%>%
  summarize(mean(MAE))
```

### Removing the only catergorical variable that has problem with GAM
```{r}
airbnb_5000_complete <- airbnb_5000_complete %>% select(-room_type)
```
Originally, the GAM algorithm does not like our airbnb_complete dataset. We thought there might be too many catergorical variables and it can't handle that much. So we started out removing multiple less significant variables out (according to the least square model). After trials and errors, we found that the only variable that had problem with GAM was room_type, so we just removed it.(Explanation?).

### Building the GAM model
```{r warning = FALSE, message = FALSE, fig.width = 8, fig.height = 12}
 # Set the seed
    set.seed(253)

 # Run the GAM
    gam_model <- train(
      price ~.,
      data = airbnb_5000_complete,
      method = "gamLoess",
      tuneGrid = data.frame(span = seq(0.1,1,length = 30), degree = 1),
      trControl = trainControl(method = "cv", number = 10, selectionFunction = "best"),
      metric = "MAE",
      na.action = na.omit
    )
```

### Showing the GAM results
```{r fig.width = 8, fig.height =12}
    # Calculate the CV MAE of the best model
    gam_model$results %>% 
      filter(span == gam_model$bestTune$span)
    gam_model$resample %>% 
      summarize(mean(MAE))
    
     # Put the 11 plots in a 4x3 grid
    par(mfrow = c(4,3))
    
    # Make plots
    plot(gam_model$finalModel)
```

### Contrast with KNN
```{r}
set.seed(253)

# Run the KNN
knn_model <- train(
  price ~ .,
  data = airbnb_5000_complete,
  preProcess = c("center","scale"),
  method = "knn",
  tuneGrid = data.frame(k = c(1:19, seq(20, 100, by = 5), seq(150, 450, by = 50))),
  trControl = trainControl(method = "cv", number = 10, selectionFunction = "best"),
  metric = "MAE",
  na.action = na.omit
)
```

### Result of KNN
```{r}

knn_model$bestTune
knn_model$results %>% 
  filter(k == knn_model$bestTune$k)
```

\
\
\
\
\



## Part 3: Summarize



\
\
\
\
\
\



## Part 4: Contributions



